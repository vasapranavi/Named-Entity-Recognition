{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy as sp\n",
    "import sklearn_crfsuite\n",
    "#importing vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         word pos_tag iob_tag\n",
      "0         The      DT  I-MISC\n",
      "1      Oxford     NNP  I-MISC\n",
      "2   Companion     NNP  I-MISC\n",
      "3          to      TO  I-MISC\n",
      "4  Philosophy     NNP  I-MISC\n"
     ]
    }
   ],
   "source": [
    "#Reading train data\n",
    "train_df = pd.read_csv(\"aij-wikiner-en-wp2\", sep=r'\\n', header=None, engine='python')\n",
    "train_df.columns = ['text']\n",
    "temp = pd.DataFrame(train_df.text.str.split(' ').tolist()).stack()\n",
    "train_df = temp.reset_index()\n",
    "del temp\n",
    "train_df.columns = [\"sentence_id\", \"no_words_in_sent\", \"text\"]\n",
    "#Splitting of train data\n",
    "train_df[['word','pos_tag', 'iob_tag']] = train_df['text'].str.split('|',expand=True)\n",
    "train_df = train_df[['word','pos_tag','iob_tag']]\n",
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    word pos_tag iob_tag\n",
      "0    010      CD  I-MISC\n",
      "1     is     VBZ       O\n",
      "2    the      DT       O\n",
      "3  tenth      JJ       O\n",
      "4  album      NN       O\n"
     ]
    }
   ],
   "source": [
    "#Reading test data\n",
    "test_data = pd.read_csv(\"wikigold.conll.txt\",sep = \"\\n\\n\",header=None, engine ='python', delimiter = ' ')\n",
    "#Assigning column names\n",
    "test_data.columns = ['word','iob_tag']\n",
    "#Calculating pos tag and adding pos column to the test data\n",
    "test_data['pos'] = nltk.pos_tag(test_data['word'])\n",
    "test_data['pos_tag'] = test_data['pos'].apply(lambda x:x[1])\n",
    "#Selecting required columns\n",
    "test_data = test_data[['word','pos_tag','iob_tag']]\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['end_of_sent'] = train_df['word'].apply(lambda x:1 if x[0]==\".\" else 0)\n",
    "train_df['is_upper'] = train_df['word'].apply(lambda x:1 if x[0].isupper() else 0)\n",
    "train_df['is_NNP'] = (train_df['pos_tag'].shift() == 'NNP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['is_NNP']  = train_df['is_NNP'].apply(lambda x:1 if x==True else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['iob_tag'] = train_df['iob_tag'].apply(lambda x:'I-PER' if x == 'B-PER'  else x)\n",
    "train_df['iob_tag'] = train_df['iob_tag'].apply(lambda x:'I-ORG' if x == 'B-ORG'  else x)\n",
    "train_df['iob_tag'] = train_df['iob_tag'].apply(lambda x:'I-MISC' if x == 'B-MISC'  else x)\n",
    "train_df['iob_tag'] = train_df['iob_tag'].apply(lambda x:'I-LOC' if x == 'B-LOC'  else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>iob_tag</th>\n",
       "      <th>end_of_sent</th>\n",
       "      <th>is_upper</th>\n",
       "      <th>is_NNP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oxford</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Companion</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Philosophy</td>\n",
       "      <td>NNP</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word pos_tag iob_tag  end_of_sent  is_upper  is_NNP\n",
       "0         The      DT  I-MISC            0         1       0\n",
       "1      Oxford     NNP  I-MISC            0         1       0\n",
       "2   Companion     NNP  I-MISC            0         1       1\n",
       "3          to      TO  I-MISC            0         0       1\n",
       "4  Philosophy     NNP  I-MISC            0         1       0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['end_of_sent'] = test_data['word'].apply(lambda x:1 if x==\".\" else 0)\n",
    "test_data['is_upper'] = test_data['word'].apply(lambda x:1 if x[0].isupper() else 0)\n",
    "test_data['is_NNP'] = (test_data['pos_tag'].shift() == 'NNP')\n",
    "test_data['is_NNP']  = test_data['is_NNP'].apply(lambda x:1 if x==True else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>iob_tag</th>\n",
       "      <th>end_of_sent</th>\n",
       "      <th>is_upper</th>\n",
       "      <th>is_NNP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010</td>\n",
       "      <td>CD</td>\n",
       "      <td>I-MISC</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tenth</td>\n",
       "      <td>JJ</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>album</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word pos_tag iob_tag  end_of_sent  is_upper  is_NNP\n",
       "0    010      CD  I-MISC            0         0       0\n",
       "1     is     VBZ       O            0         0       0\n",
       "2    the      DT       O            0         0       0\n",
       "3  tenth      JJ       O            0         0       0\n",
       "4  album      NN       O            0         0       0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating dummy variable in test as well as train\n",
    "train_df['dummy'] = train_df['word'] + ' ' + train_df['pos_tag']\n",
    "test_data['dummy'] = test_data['word'] + ' ' + test_data['pos_tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit vectorizer\n",
    "vectoriser = TfidfVectorizer()\n",
    "text = list(train_df['dummy'].values) + list(test_data['dummy'].values) \n",
    "vectoriser.fit(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_train = train_df[['end_of_sent','is_upper','is_NNP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sp.sparse.hstack((vectoriser.transform(train_df.dummy),old_train.values),format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_test = test_data[['end_of_sent','is_upper','is_NNP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_data = sp.sparse.hstack((vectoriser.transform(test_data.dummy),old_test.values),format='csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "splitting data into train and test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "y = train_df.iob_tag.values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y, test_size = 0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y)\n",
    "classes = classes.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chinnari\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1-- Epoch 1\n",
      "-- Epoch 1\n",
      "\n",
      "-- Epoch 1-- Epoch 1\n",
      "\n",
      "Norm: 220.09, NNZs: 27344, Bias: -2.020000, T: 2799724, Avg. loss: 0.018114\n",
      "Total training time: 1.25 seconds.\n",
      "Norm: 165.44, NNZs: 16902, Bias: -1.940000, T: 2799724, Avg. loss: 0.025960\n",
      "Total training time: 1.32 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    2.1s remaining:    3.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 120.17, NNZs: 12706, Bias: 1.020000, T: 2799724, Avg. loss: 0.023239\n",
      "Total training time: 1.38 seconds.\n",
      "Norm: 184.07, NNZs: 22682, Bias: -1.510000, T: 2799724, Avg. loss: 0.025662"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:    2.1s remaining:    1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total training time: 1.39 seconds.\n",
      "Norm: 189.00, NNZs: 24637, Bias: -2.040000, T: 2799724, Avg. loss: 0.036538\n",
      "Total training time: 1.44 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-LOC       0.85      0.39      0.53     24816\n",
      "      I-MISC       0.61      0.50      0.55     25920\n",
      "       I-ORG       0.62      0.55      0.58     17948\n",
      "       I-PER       0.60      0.96      0.74     28992\n",
      "           O       0.98      0.99      0.99    602255\n",
      "\n",
      "   micro avg       0.94      0.94      0.94    699931\n",
      "   macro avg       0.73      0.68      0.68    699931\n",
      "weighted avg       0.94      0.94      0.93    699931\n",
      "\n",
      "0.9374695505699847\n"
     ]
    }
   ],
   "source": [
    "#importing classifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "per = Perceptron(verbose=10, n_jobs=-1, max_iter=5)\n",
    "per.partial_fit(x_train, y_train, classes)\n",
    "print(classification_report(y_pred=per.predict(x_test), y_true=y_test, labels=classes))\n",
    "print(accuracy_score(y_pred=per.predict(x_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-LOC       0.78      0.65      0.70     24816\n",
      "      I-MISC       0.78      0.44      0.56     25920\n",
      "       I-ORG       0.73      0.48      0.58     17948\n",
      "       I-PER       0.65      0.91      0.76     28992\n",
      "           O       0.98      1.00      0.99    602255\n",
      "\n",
      "   micro avg       0.95      0.95      0.95    699931\n",
      "   macro avg       0.79      0.70      0.72    699931\n",
      "weighted avg       0.95      0.95      0.94    699931\n",
      "\n",
      "0.9474348185749738\n"
     ]
    }
   ],
   "source": [
    "#importing SGDClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier()\n",
    "sgd.partial_fit(x_train, y_train, classes);\n",
    "print(classification_report(y_pred=sgd.predict(x_test), y_true=y_test, labels=classes));\n",
    "print(accuracy_score(y_pred=sgd.predict(x_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-LOC       0.79      0.74      0.76     24816\n",
      "      I-MISC       0.77      0.50      0.60     25920\n",
      "       I-ORG       0.80      0.50      0.61     17948\n",
      "       I-PER       0.79      0.92      0.85     28992\n",
      "           O       0.98      1.00      0.99    602255\n",
      "\n",
      "   micro avg       0.95      0.95      0.95    699931\n",
      "   macro avg       0.82      0.73      0.76    699931\n",
      "weighted avg       0.95      0.95      0.95    699931\n",
      "\n",
      "0.9530982339687769\n"
     ]
    }
   ],
   "source": [
    "#importing multinomial\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.partial_fit(x_train, y_train, classes);\n",
    "print(classification_report(y_pred=nb.predict(x_test), y_true=y_test, labels=classes));\n",
    "print(accuracy_score(y_pred=nb.predict(x_test), y_true=y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In task 2 we have already read the data in test and changed it into a machine learning readable foremat. We are testing againest the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       I-LOC       0.63      0.62      0.63       967\n",
      "      I-MISC       0.55      0.41      0.47       875\n",
      "       I-ORG       0.73      0.31      0.43      1234\n",
      "       I-PER       0.57      0.87      0.69      1054\n",
      "           O       0.97      0.99      0.98     21907\n",
      "\n",
      "   micro avg       0.92      0.92      0.92     26037\n",
      "   macro avg       0.69      0.64      0.64     26037\n",
      "weighted avg       0.92      0.92      0.91     26037\n",
      "\n",
      "0.9176940507738987\n"
     ]
    }
   ],
   "source": [
    "#Pridicating the output\n",
    "print(classification_report(y_pred=nb.predict(x_test_data),y_true = test_data.iob_tag.values, labels = classes))\n",
    "print(accuracy_score(y_pred=nb.predict(x_test_data),y_true = test_data.iob_tag.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
